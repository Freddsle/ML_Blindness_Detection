{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yt2qIpGfoArV"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-21f3851f8187>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[0mtrain_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'train_images/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'path'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id_code'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'{}.png'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\train.csv'"
     ]
    }
   ],
   "source": [
    "# from IPython.display import clear_output\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import os\n",
    "# import torch\n",
    "import random\n",
    "# import seaborn as sns\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# from PIL import Image\n",
    "# from functools import partial\n",
    "# import torchvision\n",
    "# from torch import nn\n",
    "# from tqdm import tqdm\n",
    "# from collections import Counter\n",
    "# from torch.utils.data.sampler import WeightedRandomSampler\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torchvision import transforms, datasets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "def ml_for_eye_care_demo(dzn_photo):    \n",
    "    time.sleep(5)\n",
    "    return random.randrange(0, 2, 1)\n",
    "\n",
    "# def ml_for_eye_care(dzn_photo):\n",
    "#     def seed_everything(seed):\n",
    "#     random.seed(seed)\n",
    "#     os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "\n",
    "#     SEED = 999\n",
    "#     seed_everything(SEED)\n",
    "\n",
    "#     DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "#     # Data\n",
    "\n",
    "#     # A clinician has rated each image for the severity of diabetic retinopathy on a scale of 0 to 4:\n",
    "#     # - **0 - No DR**\n",
    "#     # - **1 - Mild**\n",
    "#     # - **2 - Moderate**\n",
    "#     # - **3 - Severe**\n",
    "#     # - **4 - Proliferative DR**\n",
    "\n",
    "#     # Images may contain artifacts, be out of focus, underexposed, or overexposed. \n",
    "\n",
    "#     # - train.csv - the training labels\n",
    "#     # - test.csv - the test set (you must predict the diagnosis value for these variables)\n",
    "#     # - sample_submission.csv - a sample submission file in the correct format\n",
    "#     # - train.zip - the training set images\n",
    "#     # - test.zip - the public test set images\n",
    "\n",
    "#     # Dowload directly from kaggle (kaggle.json is needed for API - put it in `/content/`):\n",
    "\n",
    "#     ! pip install kaggle\n",
    "#     ! mkdir ~/.kaggle\n",
    "#     ! cp kaggle.json ~/.kaggle/\n",
    "#     ! chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "#     clear_output()\n",
    "\n",
    "#     ! kaggle competitions download -c aptos2019-blindness-detection\n",
    "\n",
    "#     ! unzip aptos2019-blindness-detection\n",
    "#     ! rm aptos2019-blindness-detection.zip\n",
    "\n",
    "#     clear_output()\n",
    "\n",
    "#     # EDA\n",
    "\n",
    "#     train_dir = os.path.join('.','train_images/')\n",
    "#     df = pd.read_csv(os.path.join('.', 'train.csv'))\n",
    "\n",
    "#     df['path'] = df['id_code'].map(lambda x: os.path.join(train_dir,'{}.png'.format(x)))\n",
    "#     df = df.drop(columns=['id_code'])\n",
    "#     df = df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\n",
    "\n",
    "#     df.head(10)\n",
    "\n",
    "#     len_df = len(df)\n",
    "#     print(f\"There are {len_df} images in df.\")\n",
    "\n",
    "#     df.diagnosis.value_counts() \n",
    "\n",
    "#     df['diagnosis'].hist(figsize = (10, 5))\n",
    "\n",
    "#     im = Image.open(df['path'][1])\n",
    "#     width, height = im.size\n",
    "#     print(width,height) \n",
    "#     im.show()\n",
    "\n",
    "#     plt.imshow(np.asarray(im))\n",
    "\n",
    "#     # long run\n",
    "#     for i in range(len_df):\n",
    "#         img = np.array(Image.open(df['path'][i])).shape\n",
    "\n",
    "#         if img[2] != 3:\n",
    "#           print(img)\n",
    "\n",
    "#     # Load data\n",
    "\n",
    "#     RESCALE_SIZE = 384, 384\n",
    "#     BATCH_SIZE = 32\n",
    "\n",
    "#     plt.rcParams[\"figure.figsize\"] = 15, 10\n",
    "\n",
    "#     train_df, val_df = train_test_split(df, test_size=0.70,\n",
    "#                                         stratify=df.diagnosis)\n",
    "\n",
    "#     # ДЛЯ СКОРОСТИ\n",
    "#     #train_df, val_df = train_test_split(train_df, test_size=0.25,\n",
    "#     #                                    stratify=train_df.diagnosis)\n",
    "\n",
    "#     train_df.reset_index(inplace=True)\n",
    "#     val_df.reset_index(inplace=True)\n",
    "\n",
    "#     class BlindDataset(Dataset):\n",
    "#         def __init__(self, df, mode=\"train\") -> None:\n",
    "#             super().__init__()\n",
    "\n",
    "#             self.df = df\n",
    "#             self.len_ = len(self.df.path)\n",
    "#             self.mode = mode\n",
    "\n",
    "#         def __len__(self):\n",
    "#             return self.len_\n",
    "\n",
    "#         def load_sample(self, file):\n",
    "#             image = Image.open(file)\n",
    "#             image.load()\n",
    "#             return image\n",
    "\n",
    "#         def __getitem__(self, index):\n",
    "#             if self.mode == \"train\":\n",
    "#                 transform = transforms.Compose([\n",
    "#                     transforms.Resize(RESCALE_SIZE),\n",
    "#                     transforms.RandomAffine(\n",
    "#                         degrees=(-180, 180),\n",
    "#                         scale=(0.8, 1.2),\n",
    "#                         shear=(0.8, 1.2),\n",
    "#                         ),\n",
    "#                     transforms.RandomHorizontalFlip(p=0.5),\n",
    "#                     transforms.RandomVerticalFlip(p=0.5),\n",
    "#                     transforms.ColorJitter(brightness=(0.2), \n",
    "#                         contrast=(0.2),\n",
    "#                         hue=(0.1),\n",
    "#                         saturation=(0.2),\n",
    "#                         ),\n",
    "#                     transforms.ToTensor(),\n",
    "#                     transforms.Normalize([0.485, 0.456, 0.406], \n",
    "#                                          [0.229, 0.224, 0.225]),\n",
    "#                 ])\n",
    "\n",
    "#             else:\n",
    "#                 transform = transforms.Compose([\n",
    "#                     transforms.Resize(RESCALE_SIZE),\n",
    "#                     transforms.CenterCrop(384),\n",
    "#                     transforms.ToTensor(),\n",
    "#                     transforms.Normalize([0.485, 0.456, 0.406], \n",
    "#                                          [0.229, 0.224, 0.225]),\n",
    "#                 ])\n",
    "\n",
    "#             tensor_image = self.load_sample(self.df.path[index])\n",
    "#             tensor_image = transform(tensor_image)\n",
    "\n",
    "#             return tensor_image, self.df.diagnosis[index]\n",
    "\n",
    "\n",
    "#     class_numbers = Counter(train_df.diagnosis)\n",
    "#     samples_weight = torch.tensor([1 / class_numbers[i] for i in train_df.diagnosis])\n",
    "\n",
    "#     trainset = BlindDataset(train_df)\n",
    "#     valset = BlindDataset(val_df, mode=\"val\")\n",
    "\n",
    "#     sampler = WeightedRandomSampler(samples_weight.type(\"torch.DoubleTensor\"), len(samples_weight))\n",
    "\n",
    "#     trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, \n",
    "#                              sampler=sampler,\n",
    "#                              #shuffle=True, \n",
    "#                              )\n",
    "#     valloader = DataLoader(valset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "#     psum    = torch.tensor([0.0, 0.0, 0.0])\n",
    "#     psum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
    "\n",
    "#     # loop through images\n",
    "#     for inputs, y in tqdm(trainloader):\n",
    "#         psum    += inputs.sum(axis        = [0, 2, 3])\n",
    "#         psum_sq += (inputs ** 2).sum(axis = [0, 2, 3])\n",
    "\n",
    "#     # pixel count\n",
    "#     count = len(df) * RESCALE_SIZE[0] * RESCALE_SIZE[0]\n",
    "\n",
    "#     # mean and std\n",
    "#     total_mean = psum / count\n",
    "#     total_var  = (psum_sq / count) - (total_mean ** 2)\n",
    "#     total_std  = torch.sqrt(total_var)\n",
    "\n",
    "#     # output\n",
    "#     print('mean: '  + str(total_mean))\n",
    "#     print('std:  '  + str(total_std))\n",
    "\n",
    "#     # 224x224:\n",
    "#     #mean: tensor([0.3056, 0.1627, 0.0532])\n",
    "#     #std:  tensor([0.2992, 0.1616, 0.0764])\n",
    "\n",
    "#     # 728x728: \n",
    "#     #mean: tensor([0.3056, 0.1627, 0.0532])\n",
    "#     #std:  tensor([0.2997, 0.1620, 0.0768])\n",
    "\n",
    "#     # 450x450:\n",
    "#     # mean: tensor([0.3057, 0.1628, 0.0533])\n",
    "#     # std:  tensor([0.2996, 0.1619, 0.0766])\n",
    "\n",
    "#     ### Класс для тренировки и валидации\n",
    "\n",
    "#     class Trainer:\n",
    "#         def __init__(self, model, epochs, criterion,\n",
    "#                      optimizer, trainloader,\n",
    "#                      validloader, device, metric,\n",
    "#                      validate=True, scheduler=None,\n",
    "#                      verbose=2):\n",
    "\n",
    "#             self.model = model.to(device)\n",
    "#             self.epochs = epochs\n",
    "#             self.criterion = criterion\n",
    "#             self.optimizer = optimizer\n",
    "#             self.trainloader = trainloader\n",
    "#             self.validloader = validloader\n",
    "#             self.device = device\n",
    "#             self.metric = metric\n",
    "#             self.validate = validate\n",
    "#             self.verbose = verbose\n",
    "#             self.scheduler = scheduler\n",
    "#             self.get_probs = nn.Softmax(dim=0)\n",
    "#             self.train_losses = []\n",
    "#             self.valid_losses = []\n",
    "#             self.train_metrics = []\n",
    "#             self.valid_metrics = []\n",
    "\n",
    "#         def fit(self, epochs=None):\n",
    "#             if epochs is None:\n",
    "#                 epochs = self.epochs\n",
    "\n",
    "#             for epoch in range(epochs):\n",
    "#                 train_loss, train_metric = self._train(self.trainloader)\n",
    "#                 self.train_losses.append(train_loss)\n",
    "#                 self.train_metrics.append(train_metric)\n",
    "\n",
    "#                 if self.validate:\n",
    "#                     val_loss, val_metric = self._validate(self.validloader)\n",
    "#                     self.valid_losses.append(val_loss)\n",
    "#                     self.valid_metrics.append(val_metric)\n",
    "\n",
    "#                     if self.scheduler is not None:\n",
    "#                         self.scheduler.step(val_loss)\n",
    "#                 else:\n",
    "#                     val_loss = \"NO\"\n",
    "\n",
    "#                 if self.verbose > 0:\n",
    "#                     print()\n",
    "#                     print(f\"Epoch {epoch+1} out of {epochs}: Train loss = {train_loss}, validation loss = {val_loss} \\n\\\n",
    "#                                              Train metric = {train_metric}, validation metric = {val_metric}\")\n",
    "#                     print()\n",
    "\n",
    "#             return self\n",
    "\n",
    "#         def _train(self, loader):\n",
    "#             self.model.train()\n",
    "#             epoch_loss = 0\n",
    "#             epoch_preds = []\n",
    "#             epoch_targets = []\n",
    "#             for i, (inputs, targets) in enumerate(loader):\n",
    "#                 inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "#                 out = self.model(inputs)\n",
    "#                 loss = self.criterion(out, targets)\n",
    "#                 epoch_loss += loss.item()\n",
    "#                 self.optimizer.zero_grad()\n",
    "#                 loss.backward()\n",
    "\n",
    "#                 if self.verbose > 1:\n",
    "#                     print(f\"\\rTraining: batch {i+1} out of {len(loader)}\", end=\"\")\n",
    "\n",
    "#                 self.optimizer.step()\n",
    "\n",
    "#                 out = self.get_probs(out)\n",
    "#                 _, preds = torch.max(out.data, 1)\n",
    "#                 epoch_preds += list(preds.cpu())\n",
    "#                 epoch_targets += list(targets.detach().cpu())\n",
    "\n",
    "#                 self._clear_vram(inputs, targets, out)\n",
    "\n",
    "#             epoch_loss = epoch_loss/len(loader)\n",
    "#             epoch_metric = self.metric(epoch_targets, epoch_preds)\n",
    "#             print(\"\\n\", end=\"\")\n",
    "\n",
    "#             return epoch_loss, epoch_metric\n",
    "\n",
    "#         def _validate(self, loader):\n",
    "#             self.model.eval()\n",
    "#             epoch_loss = 0\n",
    "#             epoch_preds = []\n",
    "#             epoch_targets = []\n",
    "#             with torch.no_grad():\n",
    "#                 for i, (inputs, targets) in enumerate(loader):\n",
    "#                     inputs, targets = inputs.to(self.device), targets.to(self.device)              \n",
    "#                     out = self.model(inputs)\n",
    "#                     loss = self.criterion(out, targets)\n",
    "\n",
    "#                     if self.verbose > 1:\n",
    "#                         print(f\"\\rValidation: batch {i+1} out of {len(loader)}\", end=\"\")\n",
    "\n",
    "#                     epoch_loss += loss.item()\n",
    "#                     out = self.get_probs(out)\n",
    "#                     _, preds = torch.max(out.data, 1)\n",
    "#                     epoch_preds += list(preds.cpu())\n",
    "#                     epoch_targets += list(targets.detach().cpu())\n",
    "\n",
    "#                     self._clear_vram(inputs, targets, out)\n",
    "\n",
    "#             epoch_loss = epoch_loss/len(loader)\n",
    "#             epoch_metric = self.metric(epoch_targets, epoch_preds)\n",
    "#             print(\"\\n\", end=\"\")\n",
    "\n",
    "#             return epoch_loss, epoch_metric\n",
    "\n",
    "#         def _clear_vram(self, inputs, labels, outputs):\n",
    "#             inputs = inputs.to(\"cpu\")\n",
    "#             labels = labels.to(\"cpu\")\n",
    "#             outputs = outputs.to(\"cpu\")\n",
    "#             del inputs, labels, outputs\n",
    "#             torch.cuda.empty_cache()\n",
    "\n",
    "#     def predict(model, loader):\n",
    "#         model.eval()\n",
    "#         predictions = []\n",
    "#         targ = []\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             for i, (inputs, targets) in enumerate(loader):\n",
    "#                 inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)              \n",
    "#                 out = model(inputs)\n",
    "#                 out = nn.functional.softmax(out, dim=-1)\n",
    "#                 _, preds = torch.max(out.data, 1)\n",
    "#                 predictions += list(preds)\n",
    "#                 targ += list(targets)\n",
    "\n",
    "#         return predictions, targ\n",
    "\n",
    "\n",
    "#     def calculate_metric(model, loader, metric=None):\n",
    "#         if metric is None:\n",
    "#             metric = accuracy_score\n",
    "\n",
    "#         preds, targets = predict(model, loader)\n",
    "#         preds = [i.item() for i in preds]\n",
    "#         targets = [i.item() for i in targets]\n",
    "\n",
    "#         return metric(targets, preds)\n",
    "\n",
    "#     # vgg19\n",
    "\n",
    "\n",
    "#     model = torchvision.models.vgg19_bn(pretrained=True)\n",
    "\n",
    "#     N_CLASSES = 5\n",
    "#     num_features = 4096\n",
    "#     model.classifier[6] = nn.Linear(num_features, N_CLASSES)\n",
    "\n",
    "#     model = model.to(DEVICE)\n",
    "\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=3, factor=0.5)\n",
    "\n",
    "#     trainer = Trainer(model, 10, criterion, optimizer, trainloader, valloader, \n",
    "#                       DEVICE, accuracy_score,\n",
    "#                       scheduler=scheduler)\n",
    "#     trainer.fit()\n",
    "\n",
    "#     sns.lineplot(y=trainer.train_losses, x=range(1, 11), label=\"Train\")\n",
    "#     sns.lineplot(y=trainer.valid_losses, x=range(1, 11), label=\"Validation\")\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "#     f1_macro = partial(f1_score, average=\"macro\")\n",
    "#     f1_micro = partial(f1_score, average=\"micro\")\n",
    "\n",
    "#     calculate_metric(model, valloader)\n",
    "#     #224x224 batch 64 - .8024017467248908\n",
    "#     # тоже, только без шаффла 0.7150655021834061\n",
    "\n",
    "#     calculate_metric(model, valloader, f1_macro)\n",
    "#     #224x224 batch 64 - .5190434141012477\n",
    "#     # тоже, только без шаффла 0.5748944091876842\n",
    "\n",
    "#     calculate_metric(model, valloader, f1_micro)\n",
    "#     #224x224 batch 64 - 0.8024017467248908\n",
    "#     # тоже, только без шаффла \n",
    "\n",
    "#     # save model\n",
    "#     torch.save(model.state_dict(), '/content/drive/MyDrive/models/vgg19.txt')\n",
    "\n",
    "#     # DenseNet169\n",
    "\n",
    "#     model = torchvision.models.densenet169(pretrained=True)\n",
    "\n",
    "#     N_CLASSES = 5\n",
    "#     num_features = 1664\n",
    "#     model.classifier = nn.Linear(num_features, N_CLASSES)\n",
    "#     model = model.to(DEVICE)\n",
    "\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=3, factor=0.5)\n",
    "\n",
    "#     trainer = Trainer(model, 10, criterion, optimizer, trainloader, valloader, \n",
    "#                       DEVICE, accuracy_score,\n",
    "#                       scheduler=scheduler)\n",
    "#     trainer.fit()\n",
    "\n",
    "#     sns.lineplot(y=trainer.train_losses, x=range(1, 11), label=\"Train\")\n",
    "#     sns.lineplot(y=trainer.valid_losses, x=range(1, 11), label=\"Validation\")\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "#     calculate_metric(model, valloader)\n",
    "#     #224x224 batch 64 - 0.8144104803493449\n",
    "#     # тоже, только без шаффла 0.7641921397379913\n",
    "\n",
    "#     calculate_metric(model, valloader, f1_macro)\n",
    "#     #224x224 batch 64 - 0.6560790065258206\n",
    "#     # тоже, только без шаффла 0.6223088864604981\n",
    "\n",
    "#     calculate_metric(model, valloader, f1_micro)\n",
    "#     #224x224 batch 64 - 0.8144104803493449\n",
    "#     # тоже, только без шаффла 0.7641921397379913\n",
    "\n",
    "#     # save model\n",
    "#     torch.save(model.state_dict(), '/content/drive/MyDrive/models/densnet169.txt')\n",
    "\n",
    "#     # DenseNet201\n",
    "\n",
    "#     model = torchvision.models.densenet201(pretrained=True)\n",
    "\n",
    "#     N_CLASSES = 5\n",
    "#     num_features = 1920\n",
    "#     model.classifier = nn.Linear(num_features, N_CLASSES)\n",
    "#     model = model.to(DEVICE)\n",
    "\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=3, factor=0.5)\n",
    "\n",
    "#     trainer = Trainer(model, 10, criterion, optimizer, trainloader, valloader, \n",
    "#                       DEVICE, accuracy_score,\n",
    "#                       scheduler=scheduler)\n",
    "#     trainer.fit()\n",
    "\n",
    "#     sns.lineplot(y=trainer.train_losses, x=range(1, 11), label=\"Train\")\n",
    "#     sns.lineplot(y=trainer.valid_losses, x=range(1, 11), label=\"Validation\")\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "#     calculate_metric(model, valloader)\n",
    "\n",
    "#     calculate_metric(model, valloader, f1_macro)\n",
    "\n",
    "#     calculate_metric(model, valloader, f1_micro)\n",
    "\n",
    "#     torch.save(model.state_dict(), '/content/drive/MyDrive/models/densnet201.txt')\n",
    "\n",
    "#     # RESNET34\n",
    "\n",
    "#     model = torchvision.models.resnet34(pretrained=True)\n",
    "\n",
    "#     N_CLASSES = 5\n",
    "#     num_features = 512\n",
    "#     model.fc = nn.Linear(num_features, N_CLASSES)\n",
    "#     model = model.to(DEVICE)\n",
    "\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=3, factor=0.5)\n",
    "\n",
    "#     trainer = Trainer(model, 10, criterion, optimizer, trainloader, valloader, \n",
    "#                       DEVICE, accuracy_score,\n",
    "#                       scheduler=scheduler)\n",
    "#     trainer.fit()\n",
    "\n",
    "#     sns.lineplot(y=trainer.train_losses, x=range(1, 11), label=\"Train\")\n",
    "#     sns.lineplot(y=trainer.valid_losses, x=range(1, 11), label=\"Validation\")\n",
    "\n",
    "#     plt.show()\n",
    "\n",
    "#     calculate_metric(model, valloader)\n",
    "#     #224x224 batch 64 - 0.8144104803493449\n",
    "#     # тоже, только без шаффла 0.7641921397379913\n",
    "\n",
    "#     calculate_metric(model, valloader, f1_macro)\n",
    "#     #224x224 batch 64 - 0.6560790065258206\n",
    "#     # тоже, только без шаффла 0.6223088864604981\n",
    "\n",
    "#     calculate_metric(model, valloader, f1_micro)\n",
    "#     #224x224 batch 64 - 0.8144104803493449\n",
    "#     # тоже, только без шаффла 0.7641921397379913\n",
    "\n",
    "#     # save model\n",
    "#     torch.save(model.state_dict(), '/content/drive/MyDrive/models/resnet34.txt')\n",
    "\n",
    "#     # Предсказание\n",
    "\n",
    "#     test_dir = os.path.join('.','test_images/')\n",
    "#     df_t = pd.read_csv(os.path.join('.', 'test.csv'))\n",
    "\n",
    "#     df_t['path'] = df_t['id_code'].map(lambda x: os.path.join(test_dir,'{}.png'.format(x)))\n",
    "#     df_t = df_t.drop(columns=['id_code'])\n",
    "#     df_t = df_t.sample(frac=1).reset_index(drop=True) #shuffle dataframe\n",
    "\n",
    "#     df_t.head(10)\n",
    "\n",
    "#     #predictions, targ\n",
    "\n",
    "#     #df = pd.DataFrame(submission, columns=[\"id_code\", \"diagnosis\"])\n",
    "#     #df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMmq20eltbg9YL5eXFwF0k5",
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "mount_file_id": "1CgKtp0m6Kr3asd27X4Gt36PML9J3APQD",
   "name": "model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
